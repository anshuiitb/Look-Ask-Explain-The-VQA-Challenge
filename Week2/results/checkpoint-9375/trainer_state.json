{
  "best_global_step": 9375,
  "best_metric": 0.9403181437627078,
  "best_model_checkpoint": "./results\\checkpoint-9375",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 9375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.032,
      "grad_norm": 5.619157791137695,
      "learning_rate": 3.96e-06,
      "loss": 0.6927,
      "step": 100
    },
    {
      "epoch": 0.064,
      "grad_norm": 5.314092636108398,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.6222,
      "step": 200
    },
    {
      "epoch": 0.096,
      "grad_norm": 8.461731910705566,
      "learning_rate": 1.196e-05,
      "loss": 0.3523,
      "step": 300
    },
    {
      "epoch": 0.128,
      "grad_norm": 41.565467834472656,
      "learning_rate": 1.5960000000000003e-05,
      "loss": 0.3232,
      "step": 400
    },
    {
      "epoch": 0.16,
      "grad_norm": 32.955894470214844,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.3689,
      "step": 500
    },
    {
      "epoch": 0.192,
      "grad_norm": 18.299266815185547,
      "learning_rate": 1.9776901408450705e-05,
      "loss": 0.3369,
      "step": 600
    },
    {
      "epoch": 0.224,
      "grad_norm": 35.780311584472656,
      "learning_rate": 1.955154929577465e-05,
      "loss": 0.3027,
      "step": 700
    },
    {
      "epoch": 0.256,
      "grad_norm": 52.185787200927734,
      "learning_rate": 1.9326197183098592e-05,
      "loss": 0.2634,
      "step": 800
    },
    {
      "epoch": 0.288,
      "grad_norm": 21.017009735107422,
      "learning_rate": 1.9100845070422538e-05,
      "loss": 0.3511,
      "step": 900
    },
    {
      "epoch": 0.32,
      "grad_norm": 14.52885913848877,
      "learning_rate": 1.887549295774648e-05,
      "loss": 0.3284,
      "step": 1000
    },
    {
      "epoch": 0.352,
      "grad_norm": 25.98762321472168,
      "learning_rate": 1.8650140845070425e-05,
      "loss": 0.2897,
      "step": 1100
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.3692608177661896,
      "learning_rate": 1.8424788732394367e-05,
      "loss": 0.3037,
      "step": 1200
    },
    {
      "epoch": 0.416,
      "grad_norm": 19.628416061401367,
      "learning_rate": 1.8199436619718312e-05,
      "loss": 0.3176,
      "step": 1300
    },
    {
      "epoch": 0.448,
      "grad_norm": 26.120393753051758,
      "learning_rate": 1.7974084507042254e-05,
      "loss": 0.2749,
      "step": 1400
    },
    {
      "epoch": 0.48,
      "grad_norm": 10.339632034301758,
      "learning_rate": 1.77487323943662e-05,
      "loss": 0.283,
      "step": 1500
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.4105055332183838,
      "learning_rate": 1.7523380281690142e-05,
      "loss": 0.2529,
      "step": 1600
    },
    {
      "epoch": 0.544,
      "grad_norm": 13.695003509521484,
      "learning_rate": 1.7298028169014084e-05,
      "loss": 0.307,
      "step": 1700
    },
    {
      "epoch": 0.576,
      "grad_norm": 6.153285980224609,
      "learning_rate": 1.707267605633803e-05,
      "loss": 0.235,
      "step": 1800
    },
    {
      "epoch": 0.608,
      "grad_norm": 1.158185362815857,
      "learning_rate": 1.684732394366197e-05,
      "loss": 0.3326,
      "step": 1900
    },
    {
      "epoch": 0.64,
      "grad_norm": 13.72269058227539,
      "learning_rate": 1.6621971830985917e-05,
      "loss": 0.2895,
      "step": 2000
    },
    {
      "epoch": 0.672,
      "grad_norm": 18.68095588684082,
      "learning_rate": 1.6396619718309862e-05,
      "loss": 0.2637,
      "step": 2100
    },
    {
      "epoch": 0.704,
      "grad_norm": 26.638187408447266,
      "learning_rate": 1.6171267605633804e-05,
      "loss": 0.2643,
      "step": 2200
    },
    {
      "epoch": 0.736,
      "grad_norm": 3.2108895778656006,
      "learning_rate": 1.594591549295775e-05,
      "loss": 0.283,
      "step": 2300
    },
    {
      "epoch": 0.768,
      "grad_norm": 6.541016578674316,
      "learning_rate": 1.572056338028169e-05,
      "loss": 0.2985,
      "step": 2400
    },
    {
      "epoch": 0.8,
      "grad_norm": 28.321134567260742,
      "learning_rate": 1.5495211267605633e-05,
      "loss": 0.2269,
      "step": 2500
    },
    {
      "epoch": 0.832,
      "grad_norm": 9.179664611816406,
      "learning_rate": 1.526985915492958e-05,
      "loss": 0.2683,
      "step": 2600
    },
    {
      "epoch": 0.864,
      "grad_norm": 10.075045585632324,
      "learning_rate": 1.5044507042253523e-05,
      "loss": 0.2273,
      "step": 2700
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.48473307490348816,
      "learning_rate": 1.4819154929577466e-05,
      "loss": 0.2655,
      "step": 2800
    },
    {
      "epoch": 0.928,
      "grad_norm": 3.268040180206299,
      "learning_rate": 1.459380281690141e-05,
      "loss": 0.2765,
      "step": 2900
    },
    {
      "epoch": 0.96,
      "grad_norm": 32.87064743041992,
      "learning_rate": 1.4368450704225354e-05,
      "loss": 0.249,
      "step": 3000
    },
    {
      "epoch": 0.992,
      "grad_norm": 22.743999481201172,
      "learning_rate": 1.4143098591549297e-05,
      "loss": 0.2714,
      "step": 3100
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.90712,
      "eval_f1": 0.9007522653445034,
      "eval_loss": 0.30634596943855286,
      "eval_runtime": 477.4512,
      "eval_samples_per_second": 52.361,
      "eval_steps_per_second": 3.274,
      "step": 3125
    },
    {
      "epoch": 1.024,
      "grad_norm": 5.611673355102539,
      "learning_rate": 1.391774647887324e-05,
      "loss": 0.1944,
      "step": 3200
    },
    {
      "epoch": 1.056,
      "grad_norm": 22.146257400512695,
      "learning_rate": 1.3692394366197183e-05,
      "loss": 0.1722,
      "step": 3300
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.3558029532432556,
      "learning_rate": 1.3467042253521128e-05,
      "loss": 0.1429,
      "step": 3400
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.3009859025478363,
      "learning_rate": 1.3241690140845072e-05,
      "loss": 0.1623,
      "step": 3500
    },
    {
      "epoch": 1.152,
      "grad_norm": 29.692331314086914,
      "learning_rate": 1.3016338028169016e-05,
      "loss": 0.1507,
      "step": 3600
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.07783088833093643,
      "learning_rate": 1.279098591549296e-05,
      "loss": 0.1669,
      "step": 3700
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.4476621747016907,
      "learning_rate": 1.2565633802816903e-05,
      "loss": 0.2005,
      "step": 3800
    },
    {
      "epoch": 1.248,
      "grad_norm": 62.908973693847656,
      "learning_rate": 1.2340281690140845e-05,
      "loss": 0.159,
      "step": 3900
    },
    {
      "epoch": 1.28,
      "grad_norm": 23.931005477905273,
      "learning_rate": 1.2114929577464789e-05,
      "loss": 0.1368,
      "step": 4000
    },
    {
      "epoch": 1.312,
      "grad_norm": 87.45491790771484,
      "learning_rate": 1.1889577464788733e-05,
      "loss": 0.1906,
      "step": 4100
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 48.33204650878906,
      "learning_rate": 1.1664225352112676e-05,
      "loss": 0.1405,
      "step": 4200
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.07139758765697479,
      "learning_rate": 1.1438873239436622e-05,
      "loss": 0.1626,
      "step": 4300
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.0508292131125927,
      "learning_rate": 1.1213521126760565e-05,
      "loss": 0.1546,
      "step": 4400
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.3396942913532257,
      "learning_rate": 1.0988169014084509e-05,
      "loss": 0.1493,
      "step": 4500
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.29943886399269104,
      "learning_rate": 1.0762816901408451e-05,
      "loss": 0.1748,
      "step": 4600
    },
    {
      "epoch": 1.504,
      "grad_norm": 4.7013468742370605,
      "learning_rate": 1.0537464788732395e-05,
      "loss": 0.2062,
      "step": 4700
    },
    {
      "epoch": 1.536,
      "grad_norm": 56.73179244995117,
      "learning_rate": 1.0312112676056338e-05,
      "loss": 0.1313,
      "step": 4800
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.05927836894989014,
      "learning_rate": 1.0086760563380282e-05,
      "loss": 0.1658,
      "step": 4900
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.09219379723072052,
      "learning_rate": 9.861408450704226e-06,
      "loss": 0.1617,
      "step": 5000
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.7442407608032227,
      "learning_rate": 9.63605633802817e-06,
      "loss": 0.1522,
      "step": 5100
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.13522902131080627,
      "learning_rate": 9.410704225352113e-06,
      "loss": 0.1704,
      "step": 5200
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.13838878273963928,
      "learning_rate": 9.185352112676057e-06,
      "loss": 0.1925,
      "step": 5300
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.0790955051779747,
      "learning_rate": 8.96e-06,
      "loss": 0.1478,
      "step": 5400
    },
    {
      "epoch": 1.76,
      "grad_norm": 106.0755844116211,
      "learning_rate": 8.734647887323944e-06,
      "loss": 0.1689,
      "step": 5500
    },
    {
      "epoch": 1.792,
      "grad_norm": 8.72134017944336,
      "learning_rate": 8.509295774647888e-06,
      "loss": 0.177,
      "step": 5600
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.05030796304345131,
      "learning_rate": 8.283943661971832e-06,
      "loss": 0.1237,
      "step": 5700
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.026221156120300293,
      "learning_rate": 8.058591549295775e-06,
      "loss": 0.1534,
      "step": 5800
    },
    {
      "epoch": 1.888,
      "grad_norm": 8.039191246032715,
      "learning_rate": 7.833239436619719e-06,
      "loss": 0.1578,
      "step": 5900
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.337721824645996,
      "learning_rate": 7.607887323943662e-06,
      "loss": 0.1557,
      "step": 6000
    },
    {
      "epoch": 1.952,
      "grad_norm": 75.46576690673828,
      "learning_rate": 7.3825352112676065e-06,
      "loss": 0.1886,
      "step": 6100
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.14238539338111877,
      "learning_rate": 7.15718309859155e-06,
      "loss": 0.1858,
      "step": 6200
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9364,
      "eval_f1": 0.9349054286416114,
      "eval_loss": 0.25227493047714233,
      "eval_runtime": 466.8798,
      "eval_samples_per_second": 53.547,
      "eval_steps_per_second": 3.348,
      "step": 6250
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.060398899018764496,
      "learning_rate": 6.931830985915493e-06,
      "loss": 0.1491,
      "step": 6300
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.029765937477350235,
      "learning_rate": 6.706478873239437e-06,
      "loss": 0.0335,
      "step": 6400
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.09096413850784302,
      "learning_rate": 6.481126760563381e-06,
      "loss": 0.0535,
      "step": 6500
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.18848229944705963,
      "learning_rate": 6.255774647887325e-06,
      "loss": 0.0589,
      "step": 6600
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.01311750803142786,
      "learning_rate": 6.030422535211268e-06,
      "loss": 0.1204,
      "step": 6700
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.06975026428699493,
      "learning_rate": 5.8050704225352115e-06,
      "loss": 0.0411,
      "step": 6800
    },
    {
      "epoch": 2.208,
      "grad_norm": 4.027155876159668,
      "learning_rate": 5.579718309859156e-06,
      "loss": 0.1227,
      "step": 6900
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.034911613911390305,
      "learning_rate": 5.3543661971831e-06,
      "loss": 0.035,
      "step": 7000
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.02063588798046112,
      "learning_rate": 5.129014084507043e-06,
      "loss": 0.0682,
      "step": 7100
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.05507543683052063,
      "learning_rate": 4.903661971830986e-06,
      "loss": 0.0892,
      "step": 7200
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.054314449429512024,
      "learning_rate": 4.67830985915493e-06,
      "loss": 0.0799,
      "step": 7300
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.039651378989219666,
      "learning_rate": 4.452957746478874e-06,
      "loss": 0.0649,
      "step": 7400
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.758467197418213,
      "learning_rate": 4.227605633802817e-06,
      "loss": 0.0454,
      "step": 7500
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.04492462798953056,
      "learning_rate": 4.002253521126761e-06,
      "loss": 0.0541,
      "step": 7600
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.028655463829636574,
      "learning_rate": 3.7769014084507043e-06,
      "loss": 0.104,
      "step": 7700
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.03654159605503082,
      "learning_rate": 3.5515492957746485e-06,
      "loss": 0.0457,
      "step": 7800
    },
    {
      "epoch": 2.528,
      "grad_norm": 1.3088078498840332,
      "learning_rate": 3.3261971830985917e-06,
      "loss": 0.1388,
      "step": 7900
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.025575585663318634,
      "learning_rate": 3.100845070422536e-06,
      "loss": 0.1068,
      "step": 8000
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.0435786210000515,
      "learning_rate": 2.875492957746479e-06,
      "loss": 0.0962,
      "step": 8100
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.06420103460550308,
      "learning_rate": 2.650140845070423e-06,
      "loss": 0.0846,
      "step": 8200
    },
    {
      "epoch": 2.656,
      "grad_norm": 16.692598342895508,
      "learning_rate": 2.4247887323943665e-06,
      "loss": 0.0711,
      "step": 8300
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.16737394034862518,
      "learning_rate": 2.1994366197183102e-06,
      "loss": 0.0895,
      "step": 8400
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.1761634796857834,
      "learning_rate": 1.974084507042254e-06,
      "loss": 0.0428,
      "step": 8500
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.014693575911223888,
      "learning_rate": 1.7487323943661974e-06,
      "loss": 0.032,
      "step": 8600
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.5121802687644958,
      "learning_rate": 1.523380281690141e-06,
      "loss": 0.0886,
      "step": 8700
    },
    {
      "epoch": 2.816,
      "grad_norm": 3.578942060470581,
      "learning_rate": 1.2980281690140848e-06,
      "loss": 0.0992,
      "step": 8800
    },
    {
      "epoch": 2.848,
      "grad_norm": 115.54004669189453,
      "learning_rate": 1.0726760563380283e-06,
      "loss": 0.0684,
      "step": 8900
    },
    {
      "epoch": 2.88,
      "grad_norm": 95.41626739501953,
      "learning_rate": 8.47323943661972e-07,
      "loss": 0.0526,
      "step": 9000
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.03484785556793213,
      "learning_rate": 6.219718309859156e-07,
      "loss": 0.0736,
      "step": 9100
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.048096559941768646,
      "learning_rate": 3.966197183098592e-07,
      "loss": 0.0497,
      "step": 9200
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.015367062762379646,
      "learning_rate": 1.7126760563380282e-07,
      "loss": 0.0444,
      "step": 9300
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.94012,
      "eval_f1": 0.9403181437627078,
      "eval_loss": 0.31598833203315735,
      "eval_runtime": 466.2062,
      "eval_samples_per_second": 53.624,
      "eval_steps_per_second": 3.353,
      "step": 9375
    }
  ],
  "logging_steps": 100,
  "max_steps": 9375,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.860035650317888e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
